\begin{thebibliography}{10}

\bibitem{brown2020language}
Tom~B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan,
  Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda
  Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan,
  Rewon Child, Aditya Ramesh, Daniel~M. Ziegler, Jeffrey Wu, Clemens Winter,
  Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray,
  Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford,
  Ilya Sutskever, and Dario Amodei.
\newblock Language models are few-shot learners, 2020.

\bibitem{devlin2019bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding, 2019.

\bibitem{ecomundo}
{Ecomundo}.
\newblock {Conformit√© internationale - Services \& Logiciels | EcoMundo}.
\newblock \url{https://www.ecomundo.eu}, 2023.
\newblock Accessed on June 5, 2023.

\bibitem{he2021deberta}
Pengcheng He, Xiaodong Liu, Jianfeng Gao, and Weizhu Chen.
\newblock Deberta: Decoding-enhanced bert with disentangled attention, 2021.

\bibitem{huggingface}
{HuggingFace}.
\newblock {The AI community building the future.}
\newblock \url{https://huggingface.co/}, 2023.

\bibitem{langchain}
{LangChain}.
\newblock {Building applications with LLMs through composability.}
\newblock \url{https://github.com/hwchase17/langchain}, 2023.

\bibitem{liu2019roberta}
Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer
  Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov.
\newblock Roberta: A robustly optimized bert pretraining approach, 2019.

\bibitem{mikolov2013efficient}
Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean.
\newblock Efficient estimation of word representations in vector space, 2013.

\bibitem{openai}
{OpenAI}.
\newblock {OpenAI}.
\newblock \url{https://openai.com/}, 2023.

\bibitem{openaiUP}
{OpenAI}.
\newblock {OpenAI Usage Policy}.
\newblock \url{https://openai.com/policies/api-data-usage-policies}, 2023.

\bibitem{NIPS2017_3f5ee243}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, \L~ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In I.~Guyon, U.~Von Luxburg, S.~Bengio, H.~Wallach, R.~Fergus,
  S.~Vishwanathan, and R.~Garnett, editors, {\em Advances in Neural Information
  Processing Systems}, volume~30. Curran Associates, Inc., 2017.

\end{thebibliography}
